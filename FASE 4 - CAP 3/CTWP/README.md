<style>
</style>

**FIAP - Faculdade de InformÃ¡tica e AdministraÃ§Ã£o Paulista**

[](https://www.fiap.com.br/)

# ğŸŒŠ Implementando algoritmos de Machine Learning com Scikit-learn

**

**Nome do grupo: Grupo XX

**

**ğŸ‘¨â€****ğŸ“ Integrantes:**

- FÃ¡tima Vilela Candal
- Guilherme Campos Hermanowski
- Gabriel Viel dos Santos Delfino
- Jonathan Willian Luft
- Matheus Alboredo Soares
  
  

**ğŸ‘©â€****ğŸ« Professores:**

**Tutor(a):  Leonardo  Ruiz Orabona

**Coordenador(a): AndrÃ©  Godoi Chiovato



**ğŸ“œ DescriÃ§Ã£o**

Este projeto visa a classificaÃ§Ã£o de variedades de grÃ£os de trigo com base em suas caracterÃ­sticas fÃ­sicas, seguindo a metodologia CRISP-DM. O processo envolve um conjunto de tarefas bem detalhadas, incluindo anÃ¡lise exploratÃ³ria dos dados, prÃ©-processamento, implementaÃ§Ã£o de algoritmos de classificaÃ§Ã£o, otimizaÃ§Ã£o de modelos e interpretaÃ§Ã£o dos resultados.



**ğŸ—‚ï¸ Estrutura do Projeto**

Os arquivos estÃ£o no GITHUB: 

https://github.com/rm563003/FIAP/tree/main/FASE%204%20-%20CAP%203

```
ğŸ“‚ FIAP/ 
â”œâ”€â”€ ğŸ“ FASE 4 - CAP 3/
â”‚     â”œâ”€â”€ ğŸ“ IMAGES/
â”‚           â””â”€â”€ CORRELACAO.png
â”‚           â””â”€â”€ HISTOGRAMA.png
â”‚           â””â”€â”€ SEPARABILIDADE DAS CLASSES.PNG
â”‚           â””â”€â”€ VARIAVEIS_RANDON_FOREST.png
â”‚   â””â”€â”€ ğŸ“„ FASE4_SEEDS.ipynb
â”‚   â””â”€â”€ ğŸ“„ README.md
â”‚   â””â”€â”€ ğŸ“„ README.pdf
â”‚   â””â”€â”€ ğŸ“„ requirements.txt
â”‚   â””â”€â”€ ğŸ“„ seeds_dataset.txt
```
  
  

**ğŸ”§ DATASET**

Os dados utilizados (seeds_dataset.txt) sÃ£o provenientes do Seeds Dataset do UCI Machine Learning Repository, que contÃ©m mediÃ§Ãµes de 210 amostras de grÃ£os de trigo, divididas em trÃªs variedades: Kama, Rosa e Canadian. Os atributos analisados
incluem Ã¡rea, perÃ­metro, compacidade, comprimento do nÃºcleo e coeficiente de
assimetria, entre outros.

Para iniciar o estudo, os dados (seeds_dataset.txt) devem ser carregados em um
ambiente de anÃ¡lise como Google Colab, permitindo a exploraÃ§Ã£o da estrutura, a
identificaÃ§Ã£o de padrÃµes e a preparaÃ§Ã£o dos dados para modelagem.

O conjunto de dados Ã© bem estruturado e adequado para anÃ¡lises de Machine Learning. Ele contÃ©m trÃªs variedades de sementes e diversas caracterÃ­sticas fÃ­sicas que podem ser usadas para classificÃ¡-las.

---

**ğŸš€ Como Executar Localmente**

1. Clone o repositÃ³rio:

```bash
git clone https://github.com/rm563003/FIAP/tree/main/FASE%204%20-%20CAP%203
cd FASE 4 - CAP 3
```

2. Instale os pacotes:

```bash
pip install -r requirements.txt
```

3. Inicie o sistema:

```bash
FASE4_SEEDS.ipynb
```

---

**ğŸ”§** **AnÃ¡lise dos resultados dos modelos de classificaÃ§Ã£o**

ğŸ”¹ Melhor desempenho geral: Random Forest

â€¢Â Â Â Â Â Â Â  Alta acurÃ¡cia (92,06%), precisÃ£o e revocaÃ§Ã£o equilibradas.

â€¢Â Â Â Â Â Â Â  Melhor AUC-ROC (98,30%), indicando excelente distinÃ§Ã£o entre classes.

â€¢Â Â Â Â Â Â Â  Menor Log Loss (0,2246), o que significa que as previsÃµes do modelo sÃ£o confiÃ¡veis.

ğŸ”¹ Bom desempenho: KNN e RegressÃ£o LogÃ­stica

â€¢Â Â Â Â Â Â Â  O KNN tem boa acurÃ¡cia (87,30%) e AUC-ROC (94,97%), mas seu Log Loss (1,8758) Ã© elevado, sugerindo previsÃµes menos confiÃ¡veis.

â€¢Â Â Â Â Â Â Â  A RegressÃ£o LogÃ­stica tem acurÃ¡cia similar Ã  SVM, mas com AUC-ROC alto (97,66%), o que indica bom poder de discriminaÃ§Ã£o.

ğŸ”¹ Desempenho intermediÃ¡rio: SVM e Naive Bayes

â€¢Â Â Â Â Â Â Â  SVM apresenta acurÃ¡cia de 85,71%, mas sem valores de AUC-ROC e Log Loss, dificultando uma avaliaÃ§Ã£o completa.

â€¢Â Â Â Â Â Â Â  Naive Bayes tem a menor acurÃ¡cia (82,54%) e um Log Loss maior (0,8231), o que pode indicar previsÃµes menos certeiras.

**ğŸ”§ ConclusÃ£o e recomendaÃ§Ãµes**

âœ… Random Forest parece ser a melhor escolha para essa tarefa, pois equilibra bem todas as mÃ©tricas.

âœ… Se a interpretabilidade for importante, RegressÃ£o LogÃ­stica pode ser uma opÃ§Ã£o sÃ³lida.

âœ… Se quiser reduzir o custo computacional, KNN pode ser Ãºtil, mas pode sofrer com previsÃµes menos confiÃ¡veis.

âœ… SVM e Naive Bayes podem ser Ãºteis dependendo da natureza dos dados, mas parecem menos eficazes aqui.



**ğŸ“‹**LicenÃ§a**

[MODELO GIT FIAP](https://github.com/agodoi/template)Â porÂ [Fiap](https://fiap.com.br/)Â estÃ¡ licenciado sobreÂ [Attribution 4.0 International](http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1).
